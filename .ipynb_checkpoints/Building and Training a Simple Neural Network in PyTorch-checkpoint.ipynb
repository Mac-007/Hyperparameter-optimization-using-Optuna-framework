{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eddf1c18-51b1-463b-b776-13141de692ea",
   "metadata": {},
   "source": [
    "<h1>Building and Training a Simple Neural Network in PyTorch</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad96c7-b01d-476c-9cd4-40e9d7578ae6",
   "metadata": {},
   "source": [
    "Now that we have a grasp on tensors and autograd, let's build a simple neural network from scratch using PyTorch.<br>\n",
    "We'll cover defining the <b>network architecture</b>,  <b>preparing the dataset</b>, <b>defining the loss function</b> and <b>optimizer</b>, and <b>training the model</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21214027-2250-4e72-b9ad-3c24f9e3b98b",
   "metadata": {},
   "source": [
    "Step-by-Step Guide to Building a Neural Network\n",
    "<ol>\n",
    "<li><b>Define the Neural Network Architecture:</b> Create a class inheriting from nn.Module.</li>\n",
    "<li><b>Prepare the Dataset:</b> Use PyTorch's Dataset and DataLoader classes.</li>\n",
    "<li><b>Define the Loss Function and Optimizer:</b> Use built-in loss functions and optimizers.</li>\n",
    "<li><b>Train the Model:</b> Implement the training loop.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9bb1e-4bb1-41c9-90c6-61af0027c6d3",
   "metadata": {},
   "source": [
    "<h4>1. Define the Neural Network Architecture</h4>\n",
    "We'll define a simple feedforward neural network with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "302bf66a-07f9-4dac-93d1-0c50c95d3b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (hidden): Linear(in_features=2, out_features=5, bias=True)\n",
      "  (output): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.hidden = nn.Linear(2, 5)  # Hidden layer with 5 neurons | 2 input features and 5 output features\n",
    "        self.output = nn.Linear(5, 1)  # Output layer | 5 input features and 1 output feature.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden(x))  # Apply ReLU activation\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the network\n",
    "net = SimpleNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e304e49-1450-48b1-933e-75f51c6e9cd2",
   "metadata": {},
   "source": [
    "<h4>2. Prepare the Dataset </h4>\n",
    "We'll create a simple synthetic dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f32b2786-3177-4f55-bdfc-7b4b9f53a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: tensor([[2., 3.],\n",
      "        [1., 2.]])\n",
      "Target: tensor([[2.],\n",
      "        [1.]])\n",
      "Data: tensor([[4., 5.],\n",
      "        [3., 4.]])\n",
      "Target: tensor([[4.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Create a synthetic dataset\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = torch.tensor([[1.0, 2.0], [2.0, 3.0], [3.0, 4.0], [4.0, 5.0]]) # (4,2)\n",
    "        self.targets = torch.tensor([[1.0], [2.0], [3.0], [4.0]]) # (4,1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "# Instantiate the dataset and dataloader\n",
    "dataset = SimpleDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)  #  Loads the dataset with specified batch size and shuffling.\n",
    "\n",
    "for data, target in dataloader:\n",
    "    print(\"Data:\", data)\n",
    "    print(\"Target:\", target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c408de66-f918-47ad-b56d-f0d5838f4d31",
   "metadata": {},
   "source": [
    "<h4> 3. Define the Loss Function and Optimizer </h4>\n",
    "We'll use Mean Squared Error (MSE) as the loss function and Stochastic Gradient Descent (SGD) as the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6eed35d-972c-45b4-9bd7-44ca75161b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()                            # Mean Squared Error (MSE)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)    # Stochastic Gradient Descent (SGD) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235f0fe-80e0-4a96-b731-c74dc9586227",
   "metadata": {},
   "source": [
    "<h4> 4. Train the Model </h4>\n",
    "Implement the training loop to train the model over multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bab0c3c8-1214-4ed8-86d0-abbc0410409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0169\n",
      "Epoch [200/1000], Loss: 0.0013\n",
      "Epoch [300/1000], Loss: 0.0002\n",
      "Epoch [400/1000], Loss: 0.0002\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data, target in dataloader:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()     # Clears gradients to avoid accumulation.\n",
    "        \n",
    "        # Forward pass\n",
    "        output = net(data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass (compute gradients)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:           # Print the loss at every 100th Epoch\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
