{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4084c79f-08ce-4402-990f-80efa503c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b11bcf1-94d2-4994-bf7d-f2784ee3c4c9",
   "metadata": {},
   "source": [
    "<h5><b>Empty Tensor:</b> Uninitialized tensor of specified size</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "99445d31-79a5-46be-939a-d8c51d32ac43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1948, 0.4773, 0.8256],\n",
      "        [0.8376, 0.4281, 0.6719],\n",
      "        [0.0138, 0.6984, 0.9841]])\n"
     ]
    }
   ],
   "source": [
    "empty_tensor = torch.empty(3,3)\n",
    "print(empty_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c376d1f-49cc-426e-b220-5331fcca2570",
   "metadata": {},
   "source": [
    "<h5><b>Random Tensor:</b> Tensor with random values.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4f3dbf54-ca30-4f62-bfaf-e22fe492062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4145, 0.8857, 0.6539],\n",
      "        [0.2171, 0.6256, 0.1076],\n",
      "        [0.5267, 0.2905, 0.7180]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,3)\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d0a4dd-7a39-41df-b66a-636788bc02bd",
   "metadata": {},
   "source": [
    "<h5><b>Tensor from Data:</b> Tensor created from existing data (e.g., list or NumPy array).</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0faf8b5a-45dc-4fd9-9525-f09f227cd559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "Data = [1,2,3,4,5,6,8,9]\n",
    "tensor_from_list = torch.tensor(Data)\n",
    "pprint(tensor_from_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1bc27df-a0e4-4a6d-ad58-76a9c9c571c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 8, 9], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np_array_data = np.array([1,2,3,4,5,6,8,9])\n",
    "tensor_from_numpy = torch.from_numpy(np_array_data)\n",
    "print(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec24f8fc-fb25-495a-b004-7b9958a20f9c",
   "metadata": {},
   "source": [
    "<h5><b>Zeros and Ones Tensors:</b> Tensors filled with zeros or ones.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa6621e3-2607-42da-a96c-e716ea356aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros(3,3)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65072433-502a-4161-99ed-465fed9036eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "ones_tensor = torch.ones(3,3)\n",
    "print(ones_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908d75d0-4412-4b19-9241-bd45f13e3b8a",
   "metadata": {},
   "source": [
    "<h3>Basic tensor operations</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4e754e-1197-4f4d-8830-63f47608a3b9",
   "metadata": {},
   "source": [
    "<h5><b>Reshape Tensors:</b> Change the shape of a tensor.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "960c11fb-27fa-4507-a69d-7f156e3b80be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped_random_tensor_2 =  tensor([[0.3724, 0.8191],\n",
      "        [0.6087, 0.6637],\n",
      "        [0.8198, 0.3716],\n",
      "        [0.5931, 0.9540],\n",
      "        [0.6736, 0.7086],\n",
      "        [0.3796, 0.7440],\n",
      "        [0.3267, 0.1912],\n",
      "        [0.4078, 0.3049],\n",
      "        [0.0314, 0.1332],\n",
      "        [0.4356, 0.2578]])\n",
      "--------------------\n",
      "reshaped_random_tensor_3 =  tensor([[0.3724, 0.8191, 0.6087, 0.6637, 0.8198],\n",
      "        [0.3716, 0.5931, 0.9540, 0.6736, 0.7086],\n",
      "        [0.3796, 0.7440, 0.3267, 0.1912, 0.4078],\n",
      "        [0.3049, 0.0314, 0.1332, 0.4356, 0.2578]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(5,4) # 20 Elements\n",
    "\n",
    "#reshaped_random_tensor = random_tensor.view(3,4) # As the original tensor size is 20 and here 3*4 = 12, which is mismatch\n",
    "\n",
    "reshaped_random_tensor_2 = random_tensor.view(10,2) # 10*2 = 20 elements\n",
    "\n",
    "reshaped_random_tensor_3 = random_tensor.view(4,5) # 4*5 = 20 elements\n",
    "\n",
    "print(\"reshaped_random_tensor_2 = \",reshaped_random_tensor_2) # 10X2 Matrix (10 Rows, 2 Columns)\n",
    "print(\"--------------------\")\n",
    "print(\"reshaped_random_tensor_3 = \",reshaped_random_tensor_3) # 4x5 Matrix (4 Rows, 5 Columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b18ffa0-c5c9-4cb8-9458-eb98facfd336",
   "metadata": {},
   "source": [
    "<h5><b>Indexing and Slicing:</b> Access specific elements or sub-tensors.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7fe5e1c5-96e6-4087-85f3-2cfe673f6488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "required_element =  tensor(6)\n",
      "third_row =  tensor([[7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "tensor_data = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(tensor_data)\n",
    "\n",
    "# Accessing 2nd Row, 3rd Column element from the given tensor data\n",
    "required_element = tensor_data[1,2] # element 6, (As indexing starts from zero, 2nd row (1), 3rd Column(2)\n",
    "print(\"required_element = \",required_element)\n",
    "\n",
    "# Slicing the given tensor data\n",
    "third_row = tensor_data[2:] # third row (As indexing starts from zero, 3rd Row (2:)) = [7,8,9]\n",
    "print(\"third_row = \",third_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd69e2-22fa-47e8-aeb4-49fff2b10038",
   "metadata": {},
   "source": [
    "<h5><b>Element-wise operations </b> such as addition or substraction or muliplication</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d68e3f63-c6aa-4923-8f33-4904b111ee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elementwise_add =  tensor([5, 7, 9])\n",
      "elementwise_sub =  tensor([3, 3, 3])\n",
      "elementwise_multiplication =  tensor([ 4, 10, 18])\n",
      "elementwise_division =  tensor([0.2500, 0.4000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "first_tensor_data = torch.tensor([1,2,3])\n",
    "second_tensor_data = torch.tensor([4,5,6])\n",
    "\n",
    "elementwise_add = first_tensor_data + second_tensor_data\n",
    "print(\"elementwise_add = \",elementwise_add)\n",
    "\n",
    "elementwise_sub = second_tensor_data - first_tensor_data\n",
    "print(\"elementwise_sub = \",elementwise_sub)\n",
    "\n",
    "elementwise_multiplication = first_tensor_data * second_tensor_data\n",
    "print(\"elementwise_multiplication = \",elementwise_multiplication)\n",
    "\n",
    "elementwise_division = first_tensor_data / second_tensor_data\n",
    "print(\"elementwise_division = \",elementwise_division)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b20886-97fb-451b-9eec-aa984df6d55f",
   "metadata": {},
   "source": [
    "<h5>Matrix concatenation</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "aefa3fa9-31ca-4189-8700-5408e9f65179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix_a:torch.Size([3, 3]) and matrix_b:torch.Size([3, 3])\n",
      "matrix_concatentation_column_wise =  tensor([[ 3, -5,  7,  7, -4,  3],\n",
      "        [ 0,  4,  8,  9, 11,  5],\n",
      "        [ 2,  1,  8, 10,  7,  0]])\n",
      "shape =  torch.Size([3, 6])\n",
      "matrix_concatentation_row_wise =  tensor([[ 3, -5,  7],\n",
      "        [ 0,  4,  8],\n",
      "        [ 2,  1,  8],\n",
      "        [ 7, -4,  3],\n",
      "        [ 9, 11,  5],\n",
      "        [10,  7,  0]])\n",
      "shape =  torch.Size([6, 3])\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Link for visualization:- https://youtu.be/RHGzUnsEHdY\n",
    "\n",
    "matrix_a = torch.tensor([[3,-5,7],[0,4,8],[2,1,8]]) # 3x3\n",
    "matrix_b = torch.tensor([[7,-4,3],[9,11,5],[10,7,0]]) # 3X3\n",
    "\n",
    "print(f\"matrix_a:{matrix_a.shape} and matrix_b:{matrix_b.shape}\")\n",
    "'''\n",
    "dim 1 = Column-wise concatentation\n",
    "dim 0 = Row-wise concatentation\n",
    "'''\n",
    "\n",
    "matrix_concatentation_column_wise = torch.cat((matrix_a,matrix_b),dim=1) # Column-wise | first matrix all column and then take second matrix all column (Youtube, example 1)\n",
    "print(\"matrix_concatentation_column_wise = \",matrix_concatentation_column_wise)\n",
    "print(\"shape = \",matrix_concatentation_column_wise.shape)\n",
    "\n",
    "\n",
    "matrix_concatentation_row_wise = torch.cat((matrix_a,matrix_b),dim=0) # Row-wise | first matrix all row and then take second matrix all row (Youtube, example 2)\n",
    "print(\"matrix_concatentation_row_wise = \",matrix_concatentation_row_wise)\n",
    "print(\"shape = \", matrix_concatentation_row_wise.shape)\n",
    "\n",
    "print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b0604-1c39-49dd-815a-11c7cf144fe4",
   "metadata": {},
   "source": [
    " <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d948d2da-f019-4666-88fd-3862fef29c14",
   "metadata": {},
   "source": [
    "<h3> Broadcasting concept in matrix </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cf0153-be68-48d4-bf84-de282ebd3562",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>    Broadcasting is a concept in numerical computing that allows arrays of different shapes to be combined in arithmetic operations.</li>\n",
    "<li>    When operating on two arrays, NumPy (and libraries like PyTorch) compares their shapes element-wise, starting with the trailing dimensions, and \"broadcasts\" the smaller array across the larger array so they have compatible shapes. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723d361-c9eb-40a6-9a18-0d42fd6bf883",
   "metadata": {},
   "source": [
    "Here’s how broadcasting works in detail:\n",
    "<ul>\n",
    "<li> <b>Rule 1:</b> If the arrays differ in their number of dimensions, the shape of the one with fewer dimensions is padded with ones on its left side.</li>\n",
    "<li> <b>Rule 2:</b> If the shape of the arrays does not match in a dimension, the array with shape equal to 1 in that dimension is stretched to match the other shape.</li>\n",
    "<li> <b>Rule 3:</b> If in any dimension the sizes disagree and neither is 1, an error is raised.</li>\n",
    "</ul>\n",
    "\n",
    "Broadcasting in PyTorch (and in NumPy) often involves applying multiple rules to ensure the shapes of the tensors are compatible for element-wise operations. The rules work together in a sequence to handle different aspects of shape compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1469d-cc3a-41ac-ad38-ac9e4e2c5972",
   "metadata": {},
   "source": [
    "<b>Rule 1: Padding with Ones:</b> Shapes with fewer dimensions are padded with ones on their left side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0a38f5a7-3d77-43b4-88a5-221cfc0c44a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 6, 7],\n",
      "        [6, 7, 8],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "matrix_a = torch.tensor([1, 2, 3])  # Shape: (3)\n",
    "Matrix_b = torch.tensor([[4], [5], [6]])  # Shape: (3, 1)\n",
    "\n",
    "# `a` is treated as (1, 3)\n",
    "result = matrix_a + Matrix_b  # Shape: (3, 3)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3367d1-54ee-4494-8c7c-634042550355",
   "metadata": {},
   "source": [
    "<b>Rule 2:</b> Stretching Dimensions: Dimensions with size 1 are stretched to match the other array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "09218897-834a-4274-a283-e30b1d79f5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  7,  8,  9, 10],\n",
      "        [12, 13, 14, 15, 16],\n",
      "        [18, 19, 20, 21, 22],\n",
      "        [24, 25, 26, 27, 28]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[1], \n",
    "                  [2], \n",
    "                  [3], \n",
    "                  [4]])\n",
    "# Shape: (4, 1)\n",
    "'''\n",
    "\"a\" need to change , so for Broadcasts to:\n",
    "a =\n",
    "[[1, 1, 1, 1, 1],  # (4, 5)\n",
    " [2, 2, 2, 2, 2],  # (4, 5)\n",
    " [3, 3, 3, 3, 3],  # (4, 5)\n",
    " [4, 4, 4, 4, 4]]  # (4, 5)\n",
    "\n",
    "b = \n",
    "[[5, 6, 7, 8, 9],  # (4, 5)\n",
    " [10, 11, 12, 13, 14],  # (4, 5)\n",
    " [15, 16, 17, 18, 19],  # (4, 5)\n",
    " [20, 21, 22, 23, 24]]  # (4, 5)\n",
    "\n",
    "a+b =\n",
    "[[ 6,  7,  8,  9, 10],\n",
    " [12, 13, 14, 15, 16],\n",
    " [18, 19, 20, 21, 22],\n",
    " [24, 25, 26, 27, 28]]\n",
    "\n",
    "'''\n",
    "\n",
    "b = torch.tensor([[5, 6, 7, 8, 9], \n",
    "                  [10, 11, 12, 13, 14], \n",
    "                  [15, 16, 17, 18, 19], \n",
    "                  [20, 21, 22, 23, 24]])\n",
    "# Shape: (4, 5)\n",
    "'''\n",
    "For broadcasting to work, \"a\" needs to be adjusted to match the shape of \"b\". \n",
    "Specifically, the dimension with size 1 in a needs to be stretched to match the size of b in that dimension.\n",
    "\n",
    "Tensor a will be stretched from shape (4, 1) to (4, 5) to match b.\n",
    "Tensor b remains unchanged.\n",
    "'''\n",
    "\n",
    "result = a + b\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8be4e9-1e64-477c-bccf-35a0a4032b79",
   "metadata": {},
   "source": [
    "<b>Rule 3:</b> Incompatible Dimensions: If dimensions differ and neither is 1, an error is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "330da734-10a8-4866-ae2c-2791a73abcdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[291], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m Matrix_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m])         \u001b[38;5;66;03m# Shape: (3)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# This will raise an error because the shapes are incompatible\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m matrix_a \u001b[38;5;241m+\u001b[39m Matrix_b\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# RuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "matrix_a = torch.tensor([[1, 2], [3, 4]])  # Shape: (2, 2)\n",
    "Matrix_b = torch.tensor([5, 6, 7])         # Shape: (3)\n",
    "\n",
    "# This will raise an error because the shapes are incompatible\n",
    "result = matrix_a + Matrix_b\n",
    "# RuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b419acf-ae9c-4f2b-af3a-7ada01ca935a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6a3ec0-183f-45a6-9f90-f690a138bce8",
   "metadata": {},
   "source": [
    "<b>Example with 1-D and 2-D Tensors</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2caecb27-3b18-4eef-bc71-40894f0a8618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix_a:torch.Size([3]) and matrix_b:torch.Size([3, 1])\n",
      "\n",
      "tensor([[11, 12, 13],\n",
      "        [21, 22, 23],\n",
      "        [31, 32, 33]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "matrix_a = torch.tensor([1, 2, 3])           # Shape: (3)\n",
    "matrix_b = torch.tensor([[10], [20], [30]])  # Shape: (3, 1)\n",
    "\n",
    "print(f\"matrix_a:{matrix_a.shape} and matrix_b:{matrix_b.shape}\\n\")\n",
    "\n",
    "# Broadcasting `a` to shape (3, 3) and `b` to shape (3, 3)\n",
    "result = matrix_a + matrix_b\n",
    "\n",
    "print(result)\n",
    "\n",
    "'''\n",
    "In above example , where we have a 1-D tensor and a 2-D tensor:\n",
    "\n",
    "The broadcasting rules followed are:\n",
    "\n",
    "1. Padding with Ones (Rule 1):\n",
    "    - The 1-D tensor `a` with shape (3) is treated as (1, 3) by padding a leading dimension of size 1.\n",
    "    - Now, the shapes are:\n",
    "      - `a`: (1, 3)\n",
    "      - `b`: (3, 1)\n",
    "\n",
    "2. Stretching Dimensions (Rule 2):\n",
    "    - The second dimension of `b` (which is 1) is stretched to match the corresponding dimension of `a` (which is 3).\n",
    "    - The first dimension of `a` (which is 1) is stretched to match the corresponding dimension of `b` (which is 3).\n",
    "    - This results in both tensors being broadcast to the shape (3, 3).\n",
    "\n",
    "Thus, the broadcasting process enables the addition of tensors `a` and `b` by making their shapes compatible. Here’s a step-by-step breakdown:\n",
    "\n",
    "- **Original shapes**:\n",
    "  - `a`: (3)\n",
    "  - `b`: (3, 1)\n",
    "\n",
    "- **After padding with ones** (Rule 1):\n",
    "  - `a`: (1, 3)\n",
    "  - `b`: (3, 1)\n",
    "\n",
    "- **After stretching dimensions** (Rule 2):\n",
    "  - `a`: (3, 3)\n",
    "  - `b`: (3, 3)\n",
    "\n",
    "The final operation results in element-wise addition of the broadcasted tensors:\n",
    "result = [[1+10, 2+10, 3+10],\n",
    "          [1+20, 2+20, 3+20],\n",
    "          [1+30, 2+30, 3+30]]\n",
    "# result is tensor([[11, 12, 13],\n",
    "#                   [21, 22, 23],\n",
    "#                   [31, 32, 33]])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716bfb88-b318-4bc1-b4d3-665071a2f8a7",
   "metadata": {},
   "source": [
    "<b>Example with 2-D and 3-D Tensors </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "43643a0b-5811-4a3a-a7ab-fa7fb7a5522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[11, 12, 13]],\n",
      "\n",
      "        [[21, 22, 23]],\n",
      "\n",
      "        [[31, 32, 33]]])\n"
     ]
    }
   ],
   "source": [
    "matrix_a = torch.tensor([[1, 2, 3]])         # Shape: (1, 3)\n",
    "matrix_b = torch.tensor([[[10]], [[20]], [[30]]])  # Shape: (3, 1, 1)\n",
    "\n",
    "# Broadcasting `a` to shape (3, 1, 3) and `b` to shape (3, 1, 3)\n",
    "result = matrix_a + matrix_b\n",
    "print(result)\n",
    "\n",
    "'''\n",
    "In above example, where we have a 2-D tensor and a 3-D tensor:\n",
    "\n",
    "The broadcasting rules followed are:\n",
    "\n",
    "1. **Padding with Ones (Rule 1)**:\n",
    "   - The tensor `a` has shape `(1, 3)`, and tensor `b` has shape `(3, 1, 1)`.\n",
    "   - The tensor `a` is treated as having shape `(1, 1, 3)` to facilitate broadcasting. This is done by adding leading dimensions of size 1.\n",
    "\n",
    "2. **Stretching Dimensions (Rule 2)**:\n",
    "   - Now, with the shapes adjusted to `(1, 1, 3)` for `a` and `(3, 1, 1)` for `b`, we need to match dimensions:\n",
    "     - The trailing dimensions are compared: (3) with (1, 3), which matches.\n",
    "     - The middle dimensions are compared: (1) with (1), which matches.\n",
    "     - The leading dimensions are compared: (1) with (3). Here, the dimension of size 1 in `a` is stretched to match the size 3 in `b`.\n",
    "\n",
    "Thus, the broadcasting process ensures that both tensors have the shape `(3, 1, 3)`:\n",
    "\n",
    "- **Original shapes**:\n",
    "  - `a`: (1, 3)\n",
    "  - `b`: (3, 1, 1)\n",
    "\n",
    "- **After padding with ones** (Rule 1):\n",
    "  - `a`: (1, 1, 3)\n",
    "  - `b`: (3, 1, 1)\n",
    "\n",
    "- **After stretching dimensions** (Rule 2):\n",
    "  - `a`: (3, 1, 3)\n",
    "  - `b`: (3, 1, 3)\n",
    "\n",
    "In the result, `a` and `b` are broadcasted to shape `(3, 1, 3)` for the element-wise addition. The result is:\n",
    "\n",
    "```python\n",
    "result = [[[1+10, 2+10, 3+10]],   # For the first slice\n",
    "          [[1+20, 2+20, 3+20]],   # For the second slice\n",
    "          [[1+30, 2+30, 3+30]]]   # For the third slice\n",
    "# result is tensor([[[11, 12, 13]],\n",
    "#                   [[21, 22, 23]],\n",
    "#                   [[31, 32, 33]]])\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Padding with Ones** (Rule 1) adjusts the shapes by adding dimensions of size 1 where necessary.\n",
    "- **Stretching Dimensions** (Rule 2) aligns the dimensions by stretching dimensions of size 1 to match the other tensor's size.\n",
    "\n",
    "These rules are applied in sequence to ensure the tensors are compatible for broadcasting and element-wise operations.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35e40b-a010-41d2-9cb4-b3d5c3fadb2b",
   "metadata": {},
   "source": [
    "<b>Example with Incompatible Shapes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f7921eee-0676-451f-a2c4-f45a5e9ac999",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[277], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m matrix_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m])         \u001b[38;5;66;03m# Shape: (2)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# This will raise an error because the shapes are incompatible\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m matrix_a \u001b[38;5;241m+\u001b[39m matrix_b\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "matrix_a = torch.tensor([1, 2, 3])      # Shape: (3)\n",
    "matrix_b = torch.tensor([4, 5])         # Shape: (2)\n",
    "\n",
    "# This will raise an error because the shapes are incompatible\n",
    "result = matrix_a + matrix_b\n",
    "# RuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c35c32-9de6-4b62-bdec-2203be9ab548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280c08b-aa9a-49e8-822c-db90a782ee49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "377d412e-d8b5-4fa6-9808-e66e3467e28e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48595ad0-1034-4221-9cc0-9270bece31e7",
   "metadata": {},
   "source": [
    "<h3>Various Matrix multiplication</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d32f1c-ebd8-445d-a35c-1c0c4b687cc4",
   "metadata": {},
   "source": [
    "<h4> <b>torch.mm</b> </h4>\n",
    "<b>Function:</b> Performs matrix multiplication of two 2-D tensors (matrices).<br>\n",
    "<b>Usage:</b> torch.mm(a, b) where a and b are 2-D tensors.<br>\n",
    "<b>Requirement:</b> Both tensors must be 2-dimensional.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68044688-6f22-4acc-9b20-83f840a76bae",
   "metadata": {},
   "source": [
    "<blockquote> torch.mm(a, b) is strictly for 2-D matrix multiplication </blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ef856fa0-caa5-472b-923b-98f4c3e24424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix_a:torch.Size([2, 3]) and matrix_b:torch.Size([3, 2])\n",
      "matrix_multiplication =  tensor([[13, 13],\n",
      "        [31, 31]])\n"
     ]
    }
   ],
   "source": [
    "matrix_a = torch.tensor([[1,2,3],[4,5,6]])    # 2x3\n",
    "matrix_b = torch.tensor([[2, 2], [1, 1], [3, 3]]) # 3x2\n",
    "\n",
    "print(f\"matrix_a:{matrix_a.shape} and matrix_b:{matrix_b.shape}\")\n",
    "'''\n",
    "For matrix multiplication, the number of columns in the first matrix must match the number of rows in the second matrix.\n",
    "Here 2x3 and 3X2, (3=3), Matrix muliplication possible\n",
    "'''\n",
    "matrix_multiplication = torch.mm(matrix_a,matrix_b)  \n",
    "print(\"matrix_multiplication = \",matrix_multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d8923-5449-4175-a04d-8cb864c5c437",
   "metadata": {},
   "source": [
    "<h4> <b>torch.matmul</b> </h4>\n",
    "<b>Function:</b> Performs matrix multiplication and supports broadcasting. It generalizes the matrix multiplication to higher dimensions.<br>\n",
    "<b>Usage:</b>  torch.matmul(a, b) where a and b can be 1-D, 2-D, or higher-dimensional tensors.<br>\n",
    "<b>Behavior:</b> \n",
    "<ul>\n",
    "<li>If both tensors are 1-D, it performs the dot product.</li>\n",
    "<li>If both tensors are 2-D, it performs matrix multiplication.</li>\n",
    "<li>If one of the tensors is 1-D, it broadcasts it to 2-D before performing matrix multiplication.</li>\n",
    "<li>For tensors with dimensions greater than 2, it performs batch matrix multiplication.</li> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c02b0-a9cb-4615-a7ed-0c679837db36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0d42f47-97c5-45f3-b395-f40f34f88ecf",
   "metadata": {},
   "source": [
    " <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b4133-7b32-4e3e-9af3-af1a129d5ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864d059-44d3-4734-97fc-2dcf01f31bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d7365d-ed5f-45e4-8c65-6ef4225d5b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdde76f-4357-4b11-a72d-01d1d9d91920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5de94c-ff21-45e1-b33f-00c58cb65537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a82549-d208-4ef4-885c-fdd3868d2c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba9098-660b-4b1d-847f-e094061c2051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
